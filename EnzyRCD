#!/usr/bin/env python3
import re
import os
import sys
import time
import rdkit
import shutil
import argparse
import contextlib
import numpy as np
import pandas as pd
import enzy_htp as eh
from rdkit import Chem
from copy import deepcopy
from rdkit import RDLogger

from pathlib import Path
from pymol import cmd, stored
from typing import List, Tuple, Dict, Union
from enzy_htp.core import file_system as fs
from collections import namedtuple, defaultdict

RosettaCst = namedtuple(
    'RosettaCst',
    'rname_1 rnum_1 ratoms_1 rchain_1 rname_2 rnum_2 ratoms_2 rchain_2 constraints'
)
#TODO(CJ): move this to the rosetta interface file

RosettaCst.__doc__ = """TODO"""


class Routine:
    """Class that holds somewhat validated arguments used to run the EnzyRCD routine. Also serves
    as a temporary holding place for the current structure file and ligand temp files. Will exit if an invalid
    keyword argument is supplied to the constructor.

    Attributes:
        #TODO(CJ): do this one literally as the last step
    """
    def __init__(self, **kwargs):
        """kwargs based constructor for initializing Routine()."""
        self.start = time.time()
        self.structure = str()
        self.mutations = str()
        self.pH = float()
        self.conformer_engine = str()
        self.n_conformers = int()
        self.ligand_1 = str()
        self.l1_native = False
        self.ligand_2 = str()
        self.l2_native = False
        self.constraints = List[RosettaCst]
        self.n_structures = int()
        self.work_dir = str()
        self.top_n = int()
        self.temp_handling = str()
        self.use_cache = bool()
        self.l1_fm = dict()
        self.l2_fm = dict()
        self.option_file = str()
        self.cst_file = str()
        self.score_file = str()
        self.option_file = str()

        allowed_keywords: List[
            str] = 'structure mutations pH conformer_engine n_conformers ligand_1 ligand_2 constraints n_structures protonate_structure work_dir top_n temp_handling use_cache'.split(
            )

        bad: bool = False
        for k, v in kwargs.items():
            if k not in allowed_keywords:
                bad = True
                eh.core._LOGGER.error(f"The keyword '{k}' is invalid.")
            else:
                setattr(self, k, v)

        if bad:
            eh.core._LOGGER.error(
                f"Invalid keywords supplied to Routine() class. Allowed are: {', '.join(allowed_keywords)}"
            )
            eh.core._LOGGER.error("Exiting...")
            exit(1)

    def main(self) -> None:
        """ Main routine """
        self.init()

        self.canonicalize()

        self.mutate()

        self.prepare_ligands()

        self.place_ligands()

        self.add_constraints()

        self.relax()

        self.make_options_file()

        self.dock()

        self.report_and_cleanup()

    def report_and_cleanup(self) -> None:
        """Ending function of the routine. Logs results, time and 

        Args:
            self: The Routine() class.

        Returns:
            Nothing.
        """
        #TODO(CJ): this is the part where I will check if the constraints are
        # actually satisfied
        score_csv: str = log_results(self.score_file, self.top_n)
        handle_temp_files(self, self.l1_fm,
                          self.l2_fm if self.ligand_2 else None)
        log_elapsed_time(self)

    def make_options_file(self) -> str:
        """Function that creates the options file for a RosettaScripts run for the RosettaLigand protocol.
        Args:
            stru_file:
            self:
            lig_self_1:
            lig_self_2:
            work_dir:

        Returns:
            The path to the options file as a str().
        """

        #TODO(CJ): this should check if the stru_file is properly formatted... i.e. A, Y, Z
        work_dir = self.work_dir
        stru_file = Path(self.structure)

        if not work_dir:
            work_dir = str(stru_file.parent)

        content: List[str] = [
            "-in:file",
            f"  -s '{stru_file.name}'",
            f"  -extra_res_fa '{Path(self.l1_fm['self']).absolute()}'",
        ]

        if self.ligand_2:
            content.append(
                f"  -extra_res_fa '{Path(self.l2_fm['self']).absolute()}'", )

        content.extend([
            "-run:preserve_header",
            "-packing",
            "    -ex1",
            "    -ex2aro",
            "    -ex2 ",
            "    -no_optH false",
            "    -flip_HNQ true",
            "    -ignore_ligand_chi true",
        ])

        if self.cst_file:
            #TODO(CJ): need to add in the constraints here
            content.extend([
                "-enzdes", f"    -cstfile '{Path(self.cst_file).absolute()}'"
            ])

        selected_protocol: str = f"{Path(__file__).parent.absolute()}/xmls/"
        if self.ligand_2:
            selected_protocol += "2_ligands.xml"
        else:
            selected_protocol += "1_ligand.xml"

        content.extend([
            "-parser",
            f"   -protocol {selected_protocol}",  #TODO(CJ): fix this
            "-out",
            f"   -file:scorefile 'score.sc'",
            "   -level 200",
            f"   -nstruct {self.n_structures}",  #TODO(CJ): change this
            "   -overwrite",
            "   -path",
            f"       -all './complexes'",
        ])

        fname = Path(work_dir) / "options.txt"

        fs.write_lines(fname, content)

        fs.safe_rmdir(f"{work_dir}/complexes/")
        fs.safe_mkdir(f"{work_dir}/complexes/")

        #TODO(CJ): clean out the complexes folder if it already exists

        self.score_file: str = f"{work_dir}/complexes/score.sc"
        self.option_file = fname.absolute()

        fs.safe_rm(self.score_file)

    def dock(self) -> None:
        """

        Args:
            self: The Routine() class.

        Returns:
            Nothing.
        """
        #fs.safe_rm(score_file)
        #fs.safe_rm( l1_fm[1] )
        #fs.safe_rm( ligand_2_parameters[1] )
        start_dir: str = os.getcwd()

        os.chdir(self.work_dir)
        eh.interface.rosetta.run_rosetta_scripts([f"@{self.option_file}"])
        os.chdir(start_dir)

    def place_ligands(self) -> str:
        """Method that places the respective ligands in the structure

        Arguments:
            stru_file:
            self:

        Returns:
            A str() with the name of file you 

        """
        #TODO(CJ): need to adjust grid search size based on how confidently
        # we can place the ligands.
        #eh.core._LOGGER.info(self)
        eh.core._LOGGER.info("Beginning ligand placement protocol...")
        df: pd.DataFrame = eh.interface.pymol.collect(
            self.structure, "chain resi resn".split())
        counter = defaultdict(set)
        for i, row in df.iterrows():
            counter[row.resn].add((row.chain, row.resi))

        has_l1, has_l2 = False, False
        l2_exists: bool = bool(self.ligand_2)

        l1_status = counter.get('L01', None)
        if l1_status is None:
            eh.core._LOGGER.warning(
                "Ligand L01 NOT found in supplied structure")
        elif len(l1_status) > 1:
            eh.core._LOGGER.error(
                f"Found {len(l1_status)} L01 ligands in supplied structure. Exiting..."
            )
            exit(1)
        else:
            has_l1 = True

        if l2_exists:
            l2_status = counter.get('L02', None)
            if l2_status is None:
                eh.core._LOGGER.warning(
                    "Ligand L02 NOT found in supplied structure")
            elif len(l2_status) > 1:
                eh.core._LOGGER.error(
                    f"Found {len(l2_status)} L02 ligands in supplied structure. Exiting..."
                )
                exit(1)
            else:
                has_l2 = True

        if l2_exists:
            if has_l1 and has_l2:
                #TODO(CJ): implement errors for this stuff
                # potential issues we can have:
                # 1. placed, but atom names are NOT unique
                # 2. multiple instances of the ligands
                eh.core._LOGGER.info(
                    "L01 and L02 are already found in structure. Ligand placement can be achieved via direct transplat!"
                )
                args = [
                    ('delete', 'all'),
                    ('load', self.structure),
                    ('remove', 'resn L01'),
                    ('load', self.l1_fm['pdb']),
                    ('remove', 'resn L02'),
                    ('alter', 'resn L01', "chain='Y'")
                ]

                if self.ligand_2:
                    args.extend([
                        ('remove', 'resn L02'),
                        ('load', self.l2_fm['pdb']),
                        ('alter', 'resn L02', "chain='Z'")
                    ])   

                args.append(('save', self.structure))
                eh.interface.pymol.execute(args)
                return

            eh.core._LOGGER.info(
                "Ligands L01 and L02 were not explicitly found in the structure. Trying fallback strategies..."
            )
        else:
            if has_l1:
                eh.core._LOGGER.info(
                    "L01 is already found in the structure. No ligand placement necessary!"
                )
                return
        #OK: at this point we need to check if there are two non-
        exit(1)
        #eh.core._LOGGER.info(
        #TODO(CJ): This is where more stuff has to happen... alphafill etc
        eh.core._LOGGER.info("Finished ligand placement protocol!")
        return None

    def add_constraints(self) -> None:
        """Method that adds the supplied constraints to the PDB file that will be input to RosettaLigand. Automatically
        saves the updated .pdb file to a new file at the same location as the original file. Given input file 'path/to/file.pdb', 
        new file is 'path/to/file_csts.pdb'.

        Args:
            current_structure: str() to the .pdb containing the structure.
            self: The Routine() namedtuple() from the parse_args() function.

        Returns:
            A tuple with layout (modified_pdb, .cst file).

        """
        #TODO(CJ): should remove existing constraint remark lines in the .pdb file
        fs.check_file_exists(self.structure)

        #remove_existing_constraints()

        current_structure = Path(self.structure)
        cst_file, pdb_with_csts = str(
            current_structure.parent / "RDock.cst"
        ), f"{current_structure.parent}/{current_structure.stem}_csts.pdb"

        cst_content: List[str] = list()
        #TODO(CJ): put in some kind of header here

        res_mappings = list()

        for cidx, cst in enumerate(self.constraints):

            validate_cst(self.structure, cst)

            if cst_content:
                cst_content.append("")

            #TODO(CJ): add some nicer spacings into here
            res_mappings.append(
                f"REMARK 666 MATCH TEMPLATE {cst.rchain_1} {cst.rname_1}  {cst.rnum_1} MATCH MOTIF {cst.rchain_2} {cst.rname_2}  {cst.rnum_2}  {cidx+1}  1"
            )

            cst_content.append("CST::BEGIN")
            cst_content.append(
                f"   TEMPLATE::  ATOM_MAP: 1 atom_name: {' '.join(cst.ratoms_1)}"
            )
            cst_content.append(
                f"   TEMPLATE::  ATOM_MAP: 1 residue3: {cst.rname_1}")
            cst_content.append("")
            cst_content.append(
                f"   TEMPLATE::  ATOM_MAP: 2 atom_name: {' '.join(cst.ratoms_2)}"
            )
            cst_content.append(
                f"   TEMPLATE::  ATOM_MAP: 2 residue3: {cst.rname_2}")
            cst_content.append("")

            for ridx, rule in enumerate(cst.constraints):
                cst_content.append(
                    f"   CONSTRAINT::  {rule[0]}: {rule[1]} {rule[2]} {rule[3]} {ridx}"
                )

            cst_content.append("CST::END")

        fs.write_lines(cst_file, cst_content)

        content: List[str] = [
            "HEADER                                            xx-MMM-xx",
        ] + res_mappings
        content.extend(fs.lines_from_file(self.structure))
        fs.write_lines(pdb_with_csts, content)

        self.structure = pdb_with_csts
        self.cst_file = cst_file

    def relax(self) -> None:
        """Method that checks if the bare polypeptide chain has a RosettaEnergy <= 0.0. Disregards
        ligands. If polypeptide chain RosettaEnergy > 0, tries a simplistic relaxation that mainly
        targets replusion energy in Rosetta.
        
        Args:
            self: 
            
        Returns:
            Nothing.
    
        """
        __cmd = eh.interface.pymol.cmd
        __cmd.delete('all')
        __cmd.load(self.structure)
        __cmd.remove('resn L01')
        __cmd.remove('resn L02')
        __cmd.save('__temp.pdb')
        start_score: float = eh.interface.rosetta.score('__temp.pdb')

        if start_score >= 0.0:
            eh.core._LOGGER.info(
                f"The starting structure without ligand(s) has an REU >= 0 ({start_score:.3f}). Structure will be relaxed without ligand(s)."
            )
        elif self.mutations:
            eh.core._LOGGER.info(
                f"The structure was mutated. Structure will be relaxed wihtout ligand(s)."
            )
        elif start_score <= 0.0:
            eh.core._LOGGER.info(
                f"The starting structure without ligand(s) has a stable REU of {start_score:.3f}! No relaxation necessary."
            )
            fs.safe_rm('__temp.pdb')
            return

        df: pd.DataFrame = eh.interface.rosetta.relax(
            '__temp.pdb',
            1,
            ramp_constraints=False,
            ignore_zero_occupancy=False,
        )

        if df.total_score[0] >= 0.0:
            eh.core._LOGGER.error(
                f"The relaxed structure has an REU >= 0 ({df.total_score[0]:.3f}). Manual relaxation is needed. Exiting..."
            )
            exit(1)
        else:
            eh.core._LOGGER.info(f"New REU of {start_score:.3f} is stable!")

        fpath = Path(self.structure)
        relaxed = str(fpath.parent / f"{fpath.stem}_relaxed.pdb")

        __cmd.delete('all')
        __cmd.load(self.structure)
        __cmd.remove('chain A')
        __cmd.load(df.description[0])
        __cmd.save(fpath)
        __cmd.delete('all')

        fs.safe_rm('__temp.pdb')
        fs.safe_rm('__temp_0001.pdb')

        self.structure = relaxed

    def mutate(self) -> None:
        """Wrapper function that performs mutations specified on the specified structure file
    
        Args:
            selfs: A Routine() class.
    
        Returns:
            Nothing.
        """
        if not self.mutations:
            eh.core._LOGGER.info("No mutations found.")
            return

        eh.core._LOGGER.info(
            f"Applying mutation(s) {', '.join(self.mutations)} using Rosetta.")

        current_structure: str = eh.mutate_pdb(self.structure,
                                               mutations=self.mutation,
                                               engine='rosetta')

        self.structure = curren - structure
        eh.core._LOGGER.info(
            f"Mutagenesis complete. Current file is {current_structure}")

    def prepare_ligands(self) -> None:
        """Convenience method that fully prepares a supplied ligand for the upcoming steps/aspects of 
        the EnzyRCD pipeline. A number of temporary files are created, so the result is a dictionary
        which maps diffrent versions of the ligand to their respective local paths. Makes uses of 
        caching mode for protonation states and conformers.

        Arguments:
            molfile: Path to the input ligand file.
            res_code: The three letter PDB code for the ligand. MUST BE L01 or L02.
            self: The Routine namedtuple() that comes from the parse_args() function.

        Returns:
            A Dict[str,str] mapping different versions of the ligand to their respective local paths.

        """
        def _preparation_implementation(molfile: str, res_code: str) -> Dict[str, str]:
            """ """
            file_mapper: Dict[str, str] = {'input': str(molfile)}
            file_mapper['deprotonated'] = eh.interface.pymol.de_protonate(
                file_mapper['input'])
            try:
                file_mapper['deprotonated'] = kekulize(
                    file_mapper['deprotonated'], '.mol2')
            except rdkit.Chem.rdchem.KekulizeException as exe:
                eh.core._LOGGER.error(
                    f"Unable to kekulize molecule in '{file_mapper['deprotonated']}'. Check that the structure is valid and try again. Exiting..."
                )
                exit(1)

            file_mapper['protonated'] = eh.interface.moe.protonate(
                file_mapper['deprotonated'])
            (self_file, pdb_file) = eh.interface.rosetta.parameterize_ligand(
                file_mapper['protonated'], res_code)
            file_mapper['self'] = self_file
            file_mapper['pdb'] = pdb_file
            file_mapper['kekulized'] = kekulize(file_mapper['protonated'])

            temp = Path(file_mapper['kekulized'])
            temp = temp.parent / f"{temp.stem}_conformers.sdf"

            #TODO(CJ): count the number of sp3 atoms in the system
            if self.use_cache and temp.exists(
            ) and temp.stat().st_size > 0:  #also checking that it isn't empty
                file_mapper['conformers'] = str(temp)
                eh.core._LOGGER.info(
                    f"Using cached file {temp} for conformers...")
            else:
                file_mapper[
                    'conformers'] = eh.interface.bcl.generate_conformers(
                        file_mapper['kekulized'])

            file_mapper['conformer_library'] = fix_conformers(
                file_mapper['pdb'], file_mapper['conformers'], res_code)
            file_mapper['conformer_library'] = shutil.move(
                file_mapper['conformer_library'],
                Path(self.work_dir) /
                Path(file_mapper['conformer_library']).name)
            eh.interface.rosetta.add_conformers(
                file_mapper['self'], file_mapper['conformer_library'])

            file_mapper['self'] = shutil.move(
                file_mapper['self'],
                Path(self.work_dir) / Path(file_mapper['self']).name)
            #TODO(CJ): need to move the conformers here and set them up correctly
            return deepcopy(file_mapper)

        self.l1_fm = _preparation_implementation(self.ligand_1, "L01")
        l1_atom_mapper:Dict[str,str] = map_atoms("Y.1.L01", self.ligand_1, self.l1_fm['pdb'])

        for cidx,cst in enumerate(self.constraints):
            if cst.rchain_1 == 'Y':
                self.constraints[cidx] = RosettaCst(
                    rname_1='L01',
                    rnum_1=cst.rnum_1,
                    rchain_1=cst.rchain_1,
                    ratoms_1=list(map(lambda kk: l1_atom_mapper[kk], cst.ratoms_1)),
                    rname_2=cst.rname_2,
                    rnum_2=cst.rnum_2,
                    rchain_2=cst.rchain_2,
                    ratoms_2=cst.ratoms_2,
                    constraints=cst.constraints
                )
            
            if cst.rchain_2 == 'Y':
                self.constraints[cidx] = RosettaCst(
                    rname_1=cst.rname_1,
                    rnum_1=cst.rnum_1,
                    rchain_1=cst.rchain_1,
                    ratoms_2=list(map(lambda kk: l1_atom_mapper[kk], cst.ratoms_2)),
                    rname_2='L01',
                    rnum_2=cst.rnum_2,
                    rchain_2=cst.rchain_2,
                    ratoms_1=cst.ratoms_1,
                    constraints=cst.constraints
                )

        #TODO(CJ): need to worry about the case where atoms are deleted
        if self.ligand_2:
            self.l2_fm = _preparation_implementation(self.ligand_2, "L02")
            l2_atom_mapper:Dict[str,str] = map_atoms("Z.1.L02", self.ligand_2, self.l2_fm['pdb'])

            for cidx, cst in enumerate(self.constraints):
                if cst.rchain_1 == 'Z':
                    self.constraints[cidx] = RosettaCst(
                        rname_1='L02',
                        rnum_1=cst.rnum_1,
                        rchain_1=cst.rchain_1,
                        ratoms_1=list(map(lambda kk: l2_atom_mapper[kk], cst.ratoms_1)),
                        rname_2=cst.rname_2,
                        rnum_2=cst.rnum_2,
                        rchain_2=cst.rchain_2,
                        ratoms_2=cst.ratoms_2,
                        constraints=cst.constraints
                    )
                
                if cst.rchain_2 == 'Z':
                    self.constraints[cidx] = RosettaCst(
                        rname_1=cst.rname_1,
                        rnum_1=cst.rnum_1,
                        rchain_1=cst.rchain_1,
                        ratoms_2=list(map(lambda kk: l2_atom_mapper[kk], cst.ratoms_2)),
                        rname_2='L02',
                        rnum_2=cst.rnum_2,
                        rchain_2=cst.rchain_2,
                        ratoms_1=cst.ratoms_1,
                        constraints=cst.constraints
                    )


    def init(self) -> None:
        """Initialization function. Sets up the environment for routine execution by making all associated applications quiet and making
        the working directory if it does not exist.
    
        Args:
            params: The Routine() class.
    
        Returns:
            Nothing.
        """
        import pymol
        import pymol2
        eh.core._LOGGER.info("Initializing program...")

        eh.core._LOGGER.info("Turning off child module logging...")
        RDLogger.DisableLog('rdApp.*')
        pymol.invocation.parse_args(['pymol',
                                     '-q'])  # optional, for quiet flag
        pymol2.SingletonPyMOL().start()
        redirect_stdout()

        # making the working directory... maybe should clean this out first
        eh.core._LOGGER.info(
            f"Creating working directory '{self.work_dir}'...")
        fs.safe_mkdir(self.work_dir)

        # checking if the required elements are present
        #TODO(CJ)
        #eh.core._LOGGER.info("Checking for required packages...")
        #missing_elements:bool=False
        #
        #if not eh.interface.bcl.compatible_env_:
        #    eh.core._LOGGER.warning("Missing elements for BCL!!")
        #    missing_elements = True

        #if not eh.interface.moe.compatible_env_:
        #    eh.core._LOGGER.warning("Missing elements for MOE!!")
        #    missing_elements = True

        #if not eh.interface.rosetta.compatible_env_:
        #    eh.core._LOGGER.warning("Missing elements for Rosetta!!")
        #    missing_elements = True

        #
        #if missing_elements:
        #    eh.core._LOGGER.error("Missing environment elements. Make sure all are available in $PATH present and re-run. Exiting...")
        #    exit( 1 )

    def canonicalize(self) -> None:
        """Method that "canonicalizes" the supplied enzyme system by ensuring that it has the form:
            + chain A, required, polypeptide and MG/ZN only, breaks allowed
            + chain Y, required, one ligand named L01
            + chain Z, optional, one ligand named L02


        """
        eh.core._LOGGER.info("Canonicalizing system...")
        eh.core._LOGGER.info(f"Scanning system found in '{self.structure}'")
        df: pd.DataFrame = eh.interface.pymol.collect(
            self.structure, "chain resn resi q".split())
        df['resi'] = df.resi.astype(int)

        eh.interface.pymol.execute([
                ('delete', 'all'),
                ('load', self.structure)
        ])

        if df.resi[0] != 1:
            eh.core._LOGGER.warning(
                "First residue is not indexed to 1! Renumbering system.")
            exit(1)
            #TODO(CJ): this is where the renumbering will happen

        aa_only: Dict[str, bool] = dict(
            zip(list(df.chain.unique()), [True] * len(df.chain.unique())))

        visited = set()
        for i, row in df.iterrows():
            key = (row.chain, row.resi, row.resn)
            if key in visited:
                continue

            visited.add(key)

            if row.resn not in eh.chemical.residue.THREE_LETTER_AA_MAPPER and row.resn.upper(
            ) not in "MG ZN".split():
                aa_only[row.chain] = False
                eh.core._LOGGER.info(
                    f"Found non-amino acid residue {row.chain}.{row.resi}.{row.resn}"
                )

        if 'A' not in aa_only:
            eh.core._LOGGER.error(
                "Fatal error. EnzyRCD expects an enzyme system where chain A is only amino acids/catalytic metals. Exiting..."
            )
            exit(1)

        to_remove: List[str] = list()
        for chain_name, aa_status in aa_only.items():
            if aa_status:
                to_remove.append(chain_name)

            if chain_name == 'A':
                continue

            if aa_status:
                eh.core._LOGGER.info(
                    f"Found polypeptide only chain {chain_name}. Appending to chain A to canonicalize"
                )
                temp_df: pd.DataFrame = eh.interface.pymol.collect(
                    'memory', "chain resn resi".split())
                temp_df['resi'] = df.resi.astype(int)
                temp_df.drop_duplicates(inplace=True)
                start: int = temp_df[temp_df.chain == 'A'].resi.max() + 1
                chain_df = temp_df[temp_df.chain == chain_name]
                eh.core._LOGGER.info(
                    f"Appending {len(chain_df)} residues to end of chain A. Starting at index {start}."
                )
                for i, row in chain_df.iterrows():
                    eh.interface.pymol.execute([(
                        "alter",f"(chain {row.chain} and resi {row.resi})",f'resi="{start}";chain="A"'
                        )])
                    start += 1
                #eh.interface.pymol.execute([("alter",f"chain {chain_name}", 'chain="A"')])
        
        for tr in to_remove:
            del aa_only[tr]

        temp_df: pd.DataFrame = eh.interface.pymol.collect(
            'memory', "chain resn resi".split())
        temp_df['resi'] = df.resi.astype(int)
        temp_df.drop_duplicates(inplace=True)
        
        #print(temp_df)
        #exit( 1 )

        if not aa_only:

            if not self.ligand_1 and not self.ligand_1:
                eh.core._LOGGER.error(
                    "No ligands present in either supplied file or on the commandline. Exiting..."
                )
                exit(1)

            eh.core._LOGGER.info(
                "No ligands present in supplied structure but available in supplied ligand files."
            )

        else:
            if len(aa_only) > 2:
                eh.core._LOGGER.error(
                    f"Expected at most two non-polypeptide chains Y and Z with ligands L01 and L02, respectively. Instead, found {len(aa_only)}. Exiting..."
                )
                exit(1)

            aa_names = list(aa_only.keys())

            if len(aa_only) == 1 and aa_names != ['Y']:
                eh.core._LOGGER.info(
                    f"Found one non-polypeptide chain named {aa_names[0]}. Renaming to chain Y."
                )
                #TODO(CJ): rename the chain
                exit(1)

            if len(aa_only) == 2 and sorted(aa_names) != ['Y', 'Z']:
                eh.core._LOGGER.info(
                    f"Found two non-polypeptide chains named {aa_names[0]} and {aa_names[1]}. Renaming to chain Y and Z."
                )
                #TODO(CJ: rename the chains
                exit(1)

            if 'Y' in aa_names and not self.ligand_1:
                self.l1_native = True
                outfile = Path(self.work_dir) / 'L01.mol2'
                self.ligand_1 = outfile
                eh.core._LOGGER.info(
                    f"Chain Y is a ligand and exists but has not been separated. Exporting to '{outfile}'"
                )
                eh.interface.pymol.execute([("save", outfile, "chain Y")])

            if 'Z' in aa_names and not self.ligand_2:
                self.l2_native = True
                outfile = Path(self.work_dir) / 'L02.mol2'
                self.ligand_2 = outfile
                eh.core._LOGGER.info(
                    f"Chain Z is a ligand and exists but has not been separated. Exporting to '{outfile}'"
                )
                eh.interface.pymol.execute([("save", outfile, "chain Z")])

        q_lt_1: bool = df.q.min() < 1.00

        if q_lt_1:
            eh.core._LOGGER.info(
                f"Some occupancies are less than 1.0. Now setting all atoms to 1.0"
            )
            eh.interface.pymol.execute([('alter', 'all', 'q=1.00')])

        #TODO(CJ): apply changes to rosetta constraints
        inpath = Path(self.structure)
        outfile = Path(self.work_dir) / f"{inpath.stem}_canonical.pdb"

        eh.interface.pymol.execute([
            ("save", outfile),
            ("delete", "all"),
            ("load", outfile)
        ])

        cmd.delete('all')
        cmd.load(outfile)
        stored.holder = []
        cmd.iterate('all', 'stored.holder.append((chain, resn, resi))')
        canonical = pd.DataFrame(data=stored.holder, columns="chain resn resi".split())
        canonical['resi'] = canonical.resi.astype(int)
        # making sure the residues are named correctly
        just_residues = canonical.drop_duplicates()
        just_residues = just_residues[just_residues.chain!='A']

        for i,row in just_residues.iterrows():
            if row.chain == 'Y' and row.resn != 'L01':
                eh.core._LOGGER.info(f"Renaming residue Y.{row.resn}.{row.resi} to Y.L01.{row.resi}")
                eh.interface.pymol.execute([
                    ("delete", "all"),
                    ("load", outfile),
                    ("alter", "chain Y", "resn='L01'"),
                    ("save", outfile),
                    ("delete", "all"),
                ])
            
            if row.chain == 'Z' and row.resn != 'L02':
                eh.core._LOGGER.info(f"Renaming residue Z.{row.resn}.{row.resi} to Z.L01.{row.resi}")
                eh.interface.pymol.execute([
                    ("delete", "all"),
                    ("load", outfile),
                    ("alter", "chain Z", "resn='L02'"),
                    ("save", outfile),
                    ("delete", "all"),
                ])
        
        #canonical: pd.DataFrame = eh.interface.pymol.collect(
        #    outfile, "chain resn resi".split())
        #canonical['resi'] = df.resi.astype(int)
        
        for i, row in canonical.drop_duplicates().iterrows():

            if row.resn in "HID HIE HIP".split():
                eh.core._LOGGER.info(
                    f"Found AMBER-typed histidine {row.chain}.{row.resn}.{row.resi}. Changing to residue name to HIS"
                )
                
                eh.interface.pymol.execute([('alter', f"chain {row.chain} and resi {row.resi}","resn='HIS'")])


        if len(df) != len(canonical):
            eh.core._LOGGER.error(
                f"Error during canonicalization, differing number of atoms. Compare structures in {self.structure} and {outfile}. Exiting..."
            )
            exit(1)

        mapper = dict()
        for (i1, row1),(i2, row2) in zip(df.iterrows(), canonical.iterrows()):
            
            key1 = (row1.chain, row1.resn, row1.resi)
            key2 = (row2.chain, row2.resn, row2.resi)
            
            if key1 == key2:
                continue
            
            mapper[key1] = key2

        if mapper:
            eh.core._LOGGER.info(f"A total of {len(mapper)} residues had their names or indices changed. Propagating to constraints...")


        for cidx, cst in enumerate(self.constraints):
            
            key1 = (cst.rchain_1, cst.rname_1, cst.rnum_1)
            key2 = (cst.rchain_2, cst.rname_2, cst.rnum_2)
            
            change:bool = False
            
            if key1 in mapper:
                change = True
                key1 = mapper[key1]

            if key2 in mapper:
                change = True
                key2 = mapper[key2]

            if change:
                eh.core._LOGGER.info(f"Canonicalization has immpacted constratint {cidx+1}")
                self.constraints[cidx]=RosettaCst(
                    rname_1=key1[1],
                    rnum_1=key1[2],
                    rchain_1=key1[0],
                    rname_2=key2[1], 
                    rnum_2=key2[2], 
                    rchain_2=key2[0],
                    ratoms_1=cst.ratoms_1,
                    ratoms_2=cst.ratoms_2,
                    constraints=cst.constraints
                ) 

        self.structure = str(outfile)


def parse_constraints(args: Routine) -> List[RosettaCst]:
    """ TODO(CJ) """
    result: List[RosettaCst] = list()
    c_file = Path(args.constraints)

    if likely_a_file(args.constraints):
        fs.check_file_exists(c_file)

    if c_file.exists():
        content: str = fs.content_from_file(c_file)
        content = ''.join(content.split())
        if not content:
            eh.core._LOGGER.warning(
                f"The supplied file '{args.constraints}' contained no constraints. Continuing..."
            )
            return result
    else:
        content: str = args.constraints
        if not content:
            eh.core._LOGGER.warning(
                "The supplied argument for --constraints is empty. Continuing..."
            )
            return result

    for chunk in content.split('),('):
        if chunk[0] != '(':
            chunk = '(' + chunk
        if chunk[-1] != ')':
            chunk += ')'

        result.append(parse_rosetta_cst(chunk))

    return result


def likely_a_file(raw: str) -> bool:
    """Applies heuristics to guess if the supplied str() is a filepath or not. Checks if:
        + has './' 
        + has '//' 
        + has a suffix as defined by pathlib

    Args:
        raw: The candidate str() to check.
    
    Returns:
        Whether the supplied str() is likely a file based on heuristics.
    """
    if raw.find('./') != -1:
        return True

    if raw.find('//') != -1:
        return True

    temp = Path(raw)
    if len(temp.suffix):
        return True

    return False


def parse_rosetta_cst(raw: str) -> List[RosettaCst]:
    """Takes raw constraints and converts them into RosettaCst() namedtuple()'s,  
    
    Args:
        raw:

    Returns:
        A list of RosettaCst() namedtuple()'s.

    """
    raw = raw[1:-1]
    var = {'constraints': []}
    ALLOWED_CSTS: Set[str] = set(
        "distanceAB angle_A angle_B torsion_A torsion_B torsion_AB".split())

    tokens: List[str] = list(filter(len, raw.split(')(')))

    if len(tokens) < 3:
        eh.core._LOGGER.info(
            f"There must be at least 3 blocks in an individual constraint. There are only {len(tokens)} in '{raw}'. Exiting..."
        )
        exit(1)

    for tidx, tk in enumerate(tokens):

        spl: List[str] = tk.split(',')
        if tidx < 2:
            var[f"rchain_{tidx+1}"] = spl[0]
            var[f"rnum_{tidx+1}"] = int(spl[1])
            var[f"rname_{tidx+1}"] = spl[2]
            var[f"ratoms_{tidx+1}"] = spl[3:]
        else:
            if spl[0] not in ALLOWED_CSTS:
                eh.core._LOGGER.error(
                    f"The supplied constraint type {spl[0]} is not supported. Allowed are: {', '.join(sorted(list(ALLOWED_CSTS)))}. Exiting..."
                )
                exit(1)

            temp = [spl[0]]
            for tt in spl[1:]:
                if tt.find('.') == -1:
                    temp.append(int(tt))
                else:
                    temp.append(float(tt))

            var['constraints'].append(temp)

    return RosettaCst(rname_1=var['rname_1'],
                      rnum_1=var['rnum_1'],
                      ratoms_1=var['ratoms_1'],
                      rchain_1=var['rchain_1'],
                      rname_2=var['rname_2'],
                      rnum_2=var['rnum_2'],
                      ratoms_2=var['ratoms_2'],
                      rchain_2=var['rchain_2'],
                      constraints=var['constraints'])


def redirect_stdout():
    #print "Redirecting stdout"
    sys.stdout.flush()  # <--- important when redirecting to files
    newstdout = os.dup(1)
    devnull = os.open(os.devnull, os.O_WRONLY)
    os.dup2(devnull, 1)
    os.close(devnull)
    sys.stdout = os.fdopen(newstdout, 'w')


def make_df(sele: str) -> pd.DataFrame:

    stored.holder = []

    cmd.iterate_state(
        -1, sele,
        'stored.holder.append( (name, elem, x, y, z, ID, chain, resn, resi ) )'
    )

    df = pd.DataFrame(columns='aname elem x y z ID chain resn resi'.split(),
                      data=stored.holder)
    df.sort_values(by='ID', inplace=True)
    return df.reset_index(drop=True)


def check_mutations(params) -> List[str]:
    """Function that checks if the supplied mutations are valid within the EnzyHTP framework. Takes
    in the parameters namedtuple() from the commandline parser and returns a list() of validated 
    mutation codes. Assumes that codes are ',' delimited. Will error and exit if any codes are invalid.
    Args:
        params: The namedtuple() from the ArgumentParser().
    Returns:
        The list() of validated EnzyHTP codes in correct format as str().
    """
    mutations: List[str] = list()

    if not params.mutations:
        return mutations

    error = False
    invalid_mutations: List[str] = list()

    for raw_mut in params.mutations.split(','):
        if not eh.mutation.valid_mutation(raw_mut):
            invalid_mutations.append(raw_mut)
            error = True
        mutations.append(raw_mut)

    if error:
        eh.core._LOGGER.error(
            f"The following supplied mutations are invalid: {','.join(invalid_mutations)}. Exiting..."
        )
        exit(1)

    return mutations


def check_residue_id(res_id: str) -> None:
    """Helper function that checks if a supplied string is a valid residue id in the PDB format. Supplied
    code must: 1) be three characters in length and 2) be all uppercase. Strips whitespace.
    Args:
        res_id: The residue id to check as a str().
    Returns:
        Nothing.
    """
    res_id = ''.join(res_id.split())

    if len(res_id) != 3:
        eh.core._LOGGER.error(
            f"The supplied residue id '{res_id}' is invalid. Must be 3 characters long. Exiting..."
        )
        exit(1)

    if not res_id.isupper():
        eh.core._LOGGER.error(
            f"The supplied residue id '{res_id}' is invalid. Must be uppercase. Exiting..."
        )
        exit(1)


def fix_conformers(template: str, conformers: str, res_code: str) -> str:
    """ """
    cmd.delete('all')
    cmd.load(template)
    template_df: pd.DataFrame = make_df('all')
    cmd.delete('all')

    cmd.load(conformers)
    original = cmd.get_object_list()
    assert len(original) == 1
    original = original[0]
    content: List[str] = list()
    #TODO(CJ): figure out a way to get rid of the warnings
    #redirect_stdout()
    cmd.split_states('all')

    for oidx, oo in enumerate(cmd.get_object_list()):
        if oo == original:
            continue
        df = make_df(oo)
        assert len(df) == len(template_df), f"{len(df)} {len(template_df)}"
        for (tidx, trow), (idx, row) in zip(template_df.iterrows(),
                                            df.iterrows()):
            assert trow.elem == row.elem
            cmd.alter(f"{oo} and ID {row.ID}", f"name='{trow.aname}'")
            cmd.alter(f"{oo} and ID {row.ID}", f"chain='{trow.chain}'")
            cmd.alter(f"{oo} and ID {row.ID}", f"resn='{res_code}'")

        temp_fname = f"state_{oidx}.pdb"
        cmd.save(temp_fname, oo)

        for ll in fs.lines_from_file(temp_fname):
            if ll.startswith('HETATM') or ll.startswith('ATOM'):
                content.append(ll)

        content.append('TER')
        fs.safe_rm(temp_fname)

    content.pop()
    content.append('END')

    outfile = Path(conformers).with_suffix('.pdb')
    fs.write_lines(outfile, content)
    return str(outfile)


def protonate_ligand(molfile: str) -> str:
    """ """
    local = eh.interface.pymol.convert(molfile, new_ext='.mol2')
    local = eh.interface.pymol.de_protonate(local)
    protonated = eh.interface.moe.protonate(local)
    return eh.interface.pymol.convert(protonated, new_ext='.sdf')


def log_elapsed_time(params: Routine) -> None:
    """Logs the elapsed time of the subroutine. Takes an arguments in seconds and converts it to days,
    hours, minutes, seconds, format.

    Args:

    Returns:
        Nothing.
    """
    elapsed = time.time() - params.start
    days, hours, minutes, seconds = 0, 0, 0, 0

    minutes_denom = 60
    hours_denom = minutes_denom * 60
    days_denom = hours_denom * 24

    if elapsed >= days_denom:
        days = int(elapsed / days_denom)
        elapsed //= days_denom

    if elapsed >= hours_denom:
        hours = int(elapsed / hours_denom)
        elapsed //= hours_denom

    if elapsed >= minutes_denom:
        minutes = int(elapsed / minutes_denom)
        elapsed //= minutes_denom

    seconds = int(elapsed)

    eh.core._LOGGER.info(
        f"Elapsed time: {days} days {hours} hours {minutes} minutes {seconds} seconds"
    )


def log_results(score_file: str, top_n: int) -> str:
    """ """
    df: pd.DataFrame = eh.interface.rosetta.parse_score_file(score_file)
    #show top 5
    df.sort_values(by='total_score', inplace=True)
    df.reset_index(drop=True, inplace=True)
    idx = min(top_n, len(df))
    eh.core._LOGGER.info(f"EnzyRCD run complete. Top {idx} structures are:")
    eh.core._LOGGER.info(f"No. \t    REU\t Structure")

    for i, row in df.iterrows():
        if i == idx:
            break
        eh.core._LOGGER.info(
            f"{i+1: 3}\t{row.total_score:6.2f}\t{row.description}")

    outfile: str = Path(score_file).with_suffix('.csv')
    df.to_csv(outfile, index=False)
    return outfile


def kekulize(in_file: str, out_format: str = '.sdf') -> str:
    """ """

    mol = Chem.MolFromMol2File(str(in_file),
                               removeHs=False,
                               cleanupSubstructures=False,
                               sanitize=False)

    holder = defaultdict(list)
    for bb in mol.GetBonds():
        if bb.IsInRing() or not bb.GetIsAromatic():
            continue
        holder[bb.GetBeginAtomIdx()].append(bb.GetEndAtomIdx())

    doubles = list()

    for kk, vv in holder.items():
        doubles.append((kk, np.random.choice(vv)))

    for bidx in range(mol.GetNumBonds()):
        bb = mol.GetBondWithIdx(bidx)

        if bb.IsInRing() or not bb.GetIsAromatic():
            continue
        key = (bb.GetBeginAtomIdx(), bb.GetEndAtomIdx())

        mol.GetAtomWithIdx(key[0]).SetIsAromatic(False)
        mol.GetAtomWithIdx(key[1]).SetIsAromatic(False)

        if key in doubles:
            bb.SetBondType(Chem.BondType.DOUBLE)
        else:
            bb.SetBondType(Chem.BondType.SINGLE)

    outfile = Path(in_file).with_suffix(out_format)

    if out_format == '.sdf':
        w = Chem.SDWriter(str(outfile))
        w.SetKekulize(True)
        w.write(mol)
        w.close()
    elif out_format == '.mol2':
        temp_file = Path(outfile).with_suffix('.mol')
        Chem.MolToMolFile(mol, str(temp_file))
        eh.interface.pymol.convert(temp_file, new_ext='.mol2')
        fs.safe_rm(temp_file)
    else:
        eh.core._LOGGER.error(
            f"The supplied extension {new_ext} is not supported. .sdf and .mol2 are currently supported. Exiting..."
        )
        exit(1)

    return str(outfile)


def validate_cst(start: Union[str, Path, pd.DataFrame],
                 cst: RosettaCst) -> None:
    """Function that checks if all the atoms for the supplied enzymatic constraint exist in the 
    supplied .pdb file. Logs all invalid atoms for the specific constraint and exits afterwards.

    Args:
        start: Either a str()/Path() to a .pdb file or a pandas DataFrame from one.
        cst: A RosettaCst() namedtuple().

    Returns:
        Nothing.
    """

    bad_atom: bool = False

    if type(start) == pd.DataFrame:
        df: pd.DataFrame = start
    else:
        fs.check_file_exists(str(start))
        cmd.delete('all')
        cmd.load(start)
        df: pd.DataFrame = make_df('all')
        cmd.delete('all')

    for ratom in cst.ratoms_1:

        row: pd.Series = df[(df.aname == ratom) & (df.resn == cst.rname_1) &
                            (df.resi == str(cst.rnum_1)) &
                            (df.chain == cst.rchain_1)]

        if len(row) == 0:
            eh.core._LOGGER.error(
                f'Atom {cst.rchain_1}.{cst.rnum_1}.{cst.rname_1}.{ratom} does not exist'
            )
            bad_atom = True

    for ratom in cst.ratoms_2:

        row: pd.Series = df[(df.aname == ratom) & (df.resn == cst.rname_2) &
                            (df.resi == str(cst.rnum_2)) &
                            (df.chain == cst.rchain_2)]

        if len(row) == 0:
            eh.core._LOGGER.error(
                f'Atom {cst.rchain_2}.{cst.rnum_2}.{cst.rname_2}.{ratom} does not exist'
            )
            bad_atom = True

    if bad_atom:
        eh.core._LOGGER.error("Errors in supplied constraints. Exiting...")
        exit(1)


def handle_temp_files(params: Routine, mapper1: Dict[str, str],
                      mapper2: Union[Dict[str, str], None]) -> None:
    """Method that cleans up temp files after the routine is run. Scans for temp files created for both 
    ligand1 and ligand 2 and handles them as described in the params namedtuple(). Should not throw.

    Args:
        params:
        mapper1:
        mapper2:

    Returns:
        Nothing.
    """
    for mapper in [mapper1, mapper2]:
        if not mapper:
            continue

        for ftype, fname in mapper.items():
            if ftype == 'input':
                continue

            fpath = Path(fname)
            if params.temp_handling == 'work_dir':
                #TODO(CJ): need to turn ths into a function
                shutil.move(fname, params.work_dir + "/" + str(fpath.name))
            else:
                fs.safe_rm(fname)

    fs.safe_rm(Path(params.work_dir) / "score.sc")
    fs.safe_rm(Path(params.work_dir) / "RDock.cst")
    fs.safe_rm(
        Path(params.work_dir) /
        "ROSETTA_CRASH.log")  #TODO(CJ): probably should be a rosetta thing


def parse_args() -> Routine:
    """Commandline argument parser. Performs basic checks on the inputs and slightly rearranges them. Note that other, 
    more advanced checks are performed in the canonicalize_system() function.
    
    Returns:
        A namedtuple with validated and treated arguments from the commandline.
    """
    parser = argparse.ArgumentParser()

    parser.add_argument(
        'structure',
        type=str,
        help=
        'File to the .pdb file containing the ligand/structure complex. Must exist and be in .pdb format.'
    )
    parser.add_argument(
        '--pH',
        type=float,
        default=7.0,
        help=
        'Desired pH for protonation. Default is 7.0 and must be on range [0,14].'
    )
    parser.add_argument(
        '--mutations',
        type=str,
        help=
        'The desired Mutations to apply in EnzyHTP format. If multiple, split by commas.'
    )
    parser.add_argument(
        '--conformer_engine',
        type=str,
        default='BCL',
        help=
        'Engine for generating ligand conformers. Default is \'BCL\'. Allowed values are \'BCL\' and \'MOE\'.'
    )
    parser.add_argument(
        '--n_conformers',
        type=int,
        default=100,
        help=
        'Number of conformers to generate. Default is 100. Must be positive.')
    parser.add_argument(
        '--ligand_1',
        type=str,
        help=
        'The path to ligand_1. Assumed to be substrate and must have name of L01. Note this is REQUIRED.'
    )
    parser.add_argument(
        '--ligand_2',
        type=str,
        help=
        'The path to ligand_2. Must have a name of L02. Note this is NOT REQUIRED.'
    )
    parser.add_argument(
        '--constraints',
        type=str,
        help=
        'Formatted constraints OR the path to a file with constraints int ethe same format. Not required but must exist if supplied.'
    )
    parser.add_argument(
        '--n_struct',
        type=int,
        help='Number of structures to make in the RosettaScripts portion.',
        default=50)
    parser.add_argument(
        '--protonate_structure',
        type=bool,
        default=True,
        help='Whether or not the structure should be protonated.')
    parser.add_argument(
        '--work_dir',
        type=str,
        default='work_dir',
        help='The directory where all work and temporary files are put.')
    parser.add_argument(
        '--top_n',
        type=int,
        default=20,
        help=
        'Display the top n docking conformations to stdout after the subroutine completes.'
    )
    parser.add_argument(
        '--temp_handling',
        type=str,
        default='work_dir',
        help=
        'How the temp files generated for both ligands and the original structure are handled. Allowed values are "work_dir" and "delete"'
    )
    parser.add_argument(
        '--use_cache',
        action='store_true',
        help=
        'Whether or not to use cache files when possible. Not that this DOES NOT check for pH and structure correctness currently.'
    )

    args = parser.parse_args()
    fs.check_file_exists(args.structure)

    if not Path(args.structure).suffix == '.pdb':
        eh.core._LOGGER.error(
            f'The supplied file "{args.structure}" is NOT in a .pdb format. Exiting...'
        )
        exit(1)

    if args.pH < 0.0 or args.pH > 14.0:
        eh.core._LOGGER.error(
            f'The supplied pH {args.pH:0.2f} is not in the range [0.00, 14,00]. Exiting...'
        )
        exit(1)

    if args.n_struct <= 0.0:
        eh.core._LOGGER.error(
            f'The supplied nstruct is {argsn.n_struct}. Must be greater than 0. Exiting...'
        )
        exit(1)

    if args.conformer_engine not in ["BCL", "MOE"]:
        eh.core._LOGGER.error(
            f'The supplied conformer engine "{args.conformer_engine}" is not supported. Allowed Options are BCL or MOE. Exiting...'
        )
        exit(1)

    if args.n_conformers < 0:
        eh.core._LOGGER.error(
            f'--n_conformers must be a positive value. Supplied value {args.n_conformers} is invalid. Exiting...'
        )
        exit(1)

    if args.temp_handling not in "work_dir delete".split():
        eh.core._LOGGER.error(
            f'The suuplied temp_handling value "{args.temp_handling}" is invalid. Must be either "work_dir" or "delete". Exiting...'
        )
        exit(1)

    mutations: List[str] = check_mutations(args)

    ligand_1, ligand_2 = str(), str()
    ligand_1_name, ligand_2_name = str(), str()

    if args.ligand_1:
        fs.check_file_exists(args.ligand_1)
        ligand_1 = args.ligand_1

    if args.ligand_2:
        fs.check_file_exists(args.ligand_2)
        ligand_2 = args.ligand_2

    constraints: List[RosettaCst] = list()

    if args.constraints:
        constraints = parse_constraints(args)

    return Routine(structure=args.structure,
                   pH=args.pH,
                   mutations=mutations,
                   conformer_engine=args.conformer_engine,
                   n_conformers=args.n_conformers,
                   ligand_1=ligand_1,
                   ligand_2=ligand_2,
                   constraints=constraints,
                   n_structures=args.n_struct,
                   protonate_structure=args.protonate_structure,
                   work_dir=args.work_dir,
                   top_n=args.top_n,
                   temp_handling=args.temp_handling,
                   use_cache=args.use_cache)

def map_atoms(res_name:str, fname1:str, fname2:str) -> Dict[str,str]:
    """TODO(CJ)"""
    def same(p1, p2, tol=0.01) -> bool:
        return np.sqrt(np.sum((p1-p2)**2)) <= tol
    df1:pd.DataFrame = eh.interface.pymol.collect(fname1, "name x y z".split())
    df2:pd.DataFrame = eh.interface.pymol.collect(fname2, "name x y z".split())
    df1['point'] = df1.apply(lambda row: np.array(np.array([row.x, row.y, row.z])), axis=1)
    df1.drop("x y z".split(), 1)
    df2['point'] = df2.apply(lambda row: np.array(np.array([row.x, row.y, row.z])), axis=1)
    df2.drop("x y z".split(), 1)
    mapper = dict()
    for o, orow in df1.iterrows():
        for n, nrow in df2.iterrows():
            if same(orow.point, nrow.point):
                eh.core._LOGGER.info(f"Remapped atom '{res_name}.{orow['name']}' -> '{res_name}.{nrow['name']}'")
                mapper[orow["name"]] = nrow["name"]
                break
        else:
            mapper[orow["name"]] = None

    for o, orow in df1.iterrows():
        if not orow.get("name", None):
            continue

        for n, nrow in df2.iterrows():
            if same(orow.point, nrow.point, 0.5):
                eh.core._LOGGER.info(f"Remapped atom '{res_name}.{orow['name']}' -> '{res_name}.{nrow['name']}'")
                mapper[orow["name"]] = nrow["name"]
                break
        else:
            eh.core._LOGGER.warning(f"Unable to remap '{res_name}.{orow['name']}'. Continuing...")
            mapper[orow["name"]] = None

    return mapper

if __name__ == '__main__':
    routine = parse_args()
    routine.main()
