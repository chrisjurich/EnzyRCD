#!/usr/bin/env python3
import re
import os
import sys
import time
import shutil
import argparse
import contextlib
import numpy as np
import pandas as pd 
import enzy_htp as eh
from rdkit import Chem
from pathlib import Path
from pymol import cmd, stored
from typing import List, Tuple, Dict
from enzy_htp.core import file_system as fs
from collections import namedtuple, defaultdict

import pymol2  #TODO(CJ): add this to the main enzy_htp part
import pymol.invocation

pymol.invocation.parse_args(['pymol', '-q'])  # optional, for quiet flag
pymol2.SingletonPyMOL().start()

#TODO(CJ): need to add more attributes, I think including a work_dir structure

ROOT_DIR: str = str(Path(__file__).parent.absolute())
"""Path of the root dir of the project, where the EnzyRCD script is stored."""

RosettaCst = namedtuple(
    'RosettaCst',
    'rname_1 rnum_1 ratoms_1 rchain_1 rname_2 rnum_2 ratoms_2 rchain_2 constraints'
)

RosettaCst.__doc__ = """namedtuple() that holds a Rosetta Constaint between two"""

ValidatedArgs = namedtuple(
    'ValidatedArgs',
    'structure mutations pH conformer_engine n_conformers ligand_1 ligand_2 constraints n_structures protonate_structure work_dir top_n temp_handling'
)
ValidatedArgs.__doc__ = """namedtuple() that holds the arguments from the commandline parser after being treated and validated. Has the below 
attributes:
    
    - structure: str path to the structure to do analysis on
    - mutations: the mutations to apply to the structure as str()'s (optional)
    - pH: the pH to protonate the system at
    - conformer_engine: the name of the engine to build conformers of the ligands with
    - n_conformers: the number of conformers to make for each ligand
    - ligand_1:


"""
#TODO(CJ): add documentation for the attributes -> finish this

def parse_rosetta_cst(raw: str) -> List[RosettaCst]:
    """
    
    Args:
        raw:

    Returns:
        A list of RosettaCst() namedtuple()'s.

    """
    raw = raw[1:-1]
    var = {'constraints': []}
    ALLOWED_CSTS: Set[str] = set(
        "distanceAB angle_A angle_B torsion_A torsion_B torsion_AB".split())

    tokens: List[str] = raw.split(')(')

    if len(tokens) < 3:
        eh.core._LOGGER.info(
            f"There must be at least 3 blocks in an individual constraint. There are only {len(tokens)} in '{raw}'. Exiting..."
        )
        exit(1)

    for tidx, tk in enumerate(tokens):

        spl: List[str] = tk.split(',')
        if tidx < 2:
            var[f"rchain_{tidx+1}"] = spl[0]
            var[f"rnum_{tidx+1}"] = int(spl[1])
            var[f"rname_{tidx+1}"] = spl[2]
            var[f"ratoms_{tidx+1}"] = spl[3:]
        else:
            if spl[0] not in ALLOWED_CSTS:
                eh.core._LOGGER.error(
                    f"The supplied constraint type {spl[0]} is not supported. Allowed are: {', '.join(sorted(list(ALLOWED_CSTS)))}. Exiting..."
                )
                exit(1)

            temp = [spl[0]]
            for tt in spl[1:]:
                if tt.find('.') == -1:
                    temp.append(int(tt))
                else:
                    temp.append(float(tt))

            var['constraints'].append(temp)

    return RosettaCst(rname_1=var['rname_1'],
                      rnum_1=var['rnum_1'],
                      ratoms_1=var['ratoms_1'],
                      rchain_1=var['rchain_1'],
                      rname_2=var['rname_2'],
                      rnum_2=var['rnum_2'],
                      ratoms_2=var['ratoms_2'],
                      rchain_2=var['rchain_2'],
                      constraints=var['constraints'])


def redirect_stdout():
    #print "Redirecting stdout"
    sys.stdout.flush()  # <--- important when redirecting to files
    newstdout = os.dup(1)
    devnull = os.open(os.devnull, os.O_WRONLY)
    os.dup2(devnull, 1)
    os.close(devnull)
    sys.stdout = os.fdopen(newstdout, 'w')


def make_df(sele: str) -> pd.DataFrame:
    stored.holder = []

    cmd.iterate_state(
        -1, sele,
        'stored.holder.append( (name, elem, x, y, z, ID, chain, resn ) )')

    df = pd.DataFrame(columns='aname elem x y z ID chain resn'.split(),
                      data=stored.holder)
    df.sort_values(by='ID', inplace=True)
    return df.reset_index(drop=True)


def check_mutations(params) -> List[str]:
    """Function that checks if the supplied mutations are valid within the EnzyHTP framework. Takes
    in the parameters namedtuple() from the commandline parser and returns a list() of validated 
    mutation codes. Assumes that codes are ',' delimited. Will error and exit if any codes are invalid.
    Args:
        params: The namedtuple() from the ArgumentParser().
    Returns:
        The list() of validated EnzyHTP codes in correct format as str().
    """
    mutations: List[str] = list()

    if not params.mutations:
        return mutations

    error = False
    invalid_mutations: List[str] = list()

    for raw_mut in params.mutations.split(','):
        if not eh.mutation.valid_mutation(raw_mut):
            invalid_mutations.append(raw_mut)
            error = True
        mutations.append(raw_mut)

    if error:
        eh.core._LOGGER.error(
            f"The following supplied mutations are invalid: {','.join(invalid_mutations)}. Exiting..."
        )
        exit(1)

    return mutations


def check_residue_id(res_id: str) -> None:
    """Helper function that checks if a supplied string is a valid residue id in the PDB format. Supplied
    code must: 1) be three characters in length and 2) be all uppercase. Strips whitespace.
    Args:
        res_id: The residue id to check as a str().
    Returns:
        Nothing.
    """
    res_id = ''.join(res_id.split())

    if len(res_id) != 3:
        eh.core._LOGGER.error(
            f"The supplied residue id '{res_id}' is invalid. Must be 3 characters long. Exiting..."
        )
        exit(1)

    if not res_id.isupper():
        eh.core._LOGGER.error(
            f"The supplied residue id '{res_id}' is invalid. Must be uppercase. Exiting..."
        )
        exit(1)


def parse_args() -> ValidatedArgs:
    """Commandline argument parser. Performs basic checks on the inputs and slightly rearranges them.
    Returns:
        A namedtuple with validated and treated arguments from the commandline.
    """
    parser = argparse.ArgumentParser()

    parser.add_argument(
        'structure',
        type=str,
        help=
        'File to the .pdb file containing the ligand/structure complex. Must exist and be in .pdb format.'
    )
    parser.add_argument(
        '--pH',
        type=float,
        default=7.0,
        help=
        'Desired pH for protonation. Default is 7.0 and must be on range [0,14].'
    )
    parser.add_argument(
        '--mutations',
        type=str,
        help=
        'The desired Mutations to apply in EnzyHTP format. If multiple, split by commas.'
    )
    parser.add_argument(
        '--conformer_engine',
        type=str,
        default='BCL',
        help=
        'Engine for generating ligand conformers. Default is \'BCL\'. Allowed values are \'BCL\' and \'MOE\'.'
    )
    parser.add_argument(
        '--n_conformers',
        type=int,
        default=100,
        help=
        'Number of conformers to generate. Default is 100. Must be positive.')
    parser.add_argument(
        '--ligand_1',
        type=str,
        help=
        'The path to ligand_1. Assumed to be substrate and must have name of L01. Note this is REQUIRED.'
    )
    parser.add_argument(
        '--ligand_2',
        type=str,
        help=
        'The path to ligand_2. Must have a name of L02. Note this is NOT REQUIRED.'
    )
    parser.add_argument(
        '--constraints',
        type=str,
        help='Formatted constraints OR the path to a file with constraints int ethe same format. Not required but must exist if supplied.'
    )
    parser.add_argument(
        '--n_struct',
        type=int,
        help='Number of structures to make in the RosettaScripts portion.',
        default=50)
    parser.add_argument(
        '--protonate_structure',
        type=bool,
        default=True,
        help='Whether or not the structure should be protonated.')
    parser.add_argument(
        '--work_dir',
        type=str,
        default='work_dir',
        help='The directory where all work and temporary files are put.'
    )
    parser.add_argument(
        '--top_n',
        type=int,
        default=20,
        help='Display the top n docking conformations to stdout after the subroutine completes.'
    )
    parser.add_argument(
        '--temp_handling',
        type=str,
        default='work_dir',
        help='How the temp files generated for both ligands and the original structure are handled. Allowed values are "work_dir" and "delete"'
    )

    args = parser.parse_args()
    fs.check_file_exists(args.structure)

    if not Path(args.structure).suffix == '.pdb':
        eh.core._LOGGER.error(
            f'The supplied file "{args.structure}" is NOT in a .pdb format. Exiting...'
        )
        exit(1)

    if args.pH < 0.0 or args.pH > 14.0:
        eh.core._LOGGER.error(
            f'The supplied pH {args.pH:0.2f} is not in the range [0.00, 14,00]. Exiting...'
        )
        exit(1)

    if args.n_struct <= 0.0:
        eh.core._LOGGER.error(
            f'The supplied nstruct is {argsn.n_struct}. Must be greater than 0. Exiting...'
        )
        exit(1)

    if args.conformer_engine not in ["BCL", "MOE"]:
        eh.core._LOGGER.error(
            f'The supplied conformer engine "{args.conformer_engine}" is not supported. Allowed Options are BCL or MOE. Exiting...'
        )
        exit(1)

    if args.n_conformers < 0:
        eh.core._LOGGER.error(
            f'--n_conformers must be a positive value. Supplied value {args.n_conformers} is invalid. Exiting...'
        )
        exit(1)

    if args.temp_handling not in "work_dir delete".split():
        eh.core._LOGGER.error(
            f'The suuplied temp_handling value "{args.temp_handling}" is invalid. Must be either "work_dir" or "delete". Exiting...'
        )
        exit(1)

    if not args.ligand_1:
        eh.core._LOGGER.error("--ligand_1 is a required argument.")
        exit(1)

    mutations: List[str] = check_mutations(args)

    ligand_1, ligand_2 = str(), str()
    ligand_1_name, ligand_2_name = str(), str()

    fs.check_file_exists(args.ligand_1)

    ligand_1 = args.ligand_1


    if args.ligand_2:
        fs.check_file_exists(args.ligand_2)
        ligand_2 = args.ligand_2

    constraints: List[RosettaCst] = list()

    if args.constraints:
        c_file = Path(args.constraints)
        if c_file.exists():
            content:str = fs.content_from_file(c_file)
            content = ''.join(content.split())
        else:
            content:str=args.constraints
        
        #TODO(CJ): do some kind of parsing check
        for chunk in content.split('),('):
            if chunk[0] != '(':
                chunk = '(' + chunk
            if chunk[-1] != ')':
                chunk += ')'

            constraints.append(parse_rosetta_cst(chunk))

    return ValidatedArgs(
        structure=args.structure,
        pH=args.pH,
        mutations=mutations,
        conformer_engine=args.conformer_engine,
        n_conformers=args.n_conformers,
        ligand_1=ligand_1,
        ligand_2=ligand_2,
        constraints=constraints,
        n_structures=args.n_struct,
        protonate_structure=args.protonate_structure,
        work_dir=args.work_dir,
        top_n=args.top_n,
        temp_handling=args.temp_handling)


def make_options_file(stru_file: str,
                      params: ValidatedArgs,
                      lig_params_1: str,
                      lig_params_2: str = None,
                      work_dir: str = None,
                      cst_file: str = None) -> str:
    """Function that creates the options file for a RosettaScripts run for the RosettaLigand protocol.
    Args:
        stru_file:
        params:
        lig_params_1:
        lig_params_2:
        work_dir:
        
    Returns:
        The path to the options file as a str().
    """
    #TODO(CJ): this should check if the stru_file is properly formatted... i.e. A, Y, Z
    work_dir = params.work_dir
    stru_file = Path(stru_file)

    if not work_dir:
        work_dir = str(stru_file.parent)

    content: List[str] = [
        "-in:file",
        f"  -s '{stru_file.name}'",
        f"  -extra_res_fa '{Path(lig_params_1).absolute()}'",
    ]

    if lig_params_2:
        content.append(f"  -extra_res_fa '{Path(lig_params_2).absolute()}'", )

    content.extend([
        "-run:preserve_header",
        "-packing",
        "    -ex1",
        "    -ex2aro",
        "    -ex2 ",
        "    -no_optH false",
        "    -flip_HNQ true",
        "    -ignore_ligand_chi true",
    ])

    if cst_file:
        #TODO(CJ): need to add in the constraints here
        content.extend(
            ["-enzdes", f"    -cstfile '{Path(cst_file).absolute()}'"])

    content.extend([
        "-parser",
        f"   -protocol {ROOT_DIR}/xmls/lig_dock2.xml",  #TODO(CJ): fix this
        "-out",
        f"   -file:scorefile 'score.sc'",
        "   -level 200",
        f"   -nstruct {params.n_structures}",  #TODO(CJ): change this
        "   -overwrite",
        "   -path",
        f"       -all './complexes'",
    ])

    fname = Path(work_dir) / "options.txt"

    fs.write_lines(fname, content)

    fs.safe_mkdir(f"{work_dir}/complexes/")

    scorefile: str = f"{work_dir}/complexes/score.sc"
    return (fname, scorefile)


def fix_conformers(template: str, conformers: str, res_code: str) -> str:
    """ """
    cmd.delete('all')
    cmd.load(template)
    template_df: pd.DataFrame = make_df('all')
    cmd.delete('all')

    cmd.load(conformers)
    original = cmd.get_object_list()
    assert len(original) == 1
    original = original[0]
    content: List[str] = list()
    #TODO(CJ): figure out a way to get rid of the warnings
    redirect_stdout()
    cmd.split_states('all')

    for oidx, oo in enumerate(cmd.get_object_list()):
        if oo == original:
            continue
        df = make_df(oo)
        assert len(df) == len(template_df), f"{len(df)} {len(template_df)}"
        for (tidx, trow), (idx, row) in zip(template_df.iterrows(),
                                            df.iterrows()):
            assert trow.elem == row.elem
            cmd.alter(f"{oo} and ID {row.ID}", f"name='{trow.aname}'")
            cmd.alter(f"{oo} and ID {row.ID}", f"chain='{trow.chain}'")
            cmd.alter(f"{oo} and ID {row.ID}", f"resn='{res_code}'")

        temp_fname = f"state_{oidx}.pdb"
        cmd.save(temp_fname, oo)

        for ll in fs.lines_from_file(temp_fname):
            if ll.startswith('HETATM') or ll.startswith('ATOM'):
                content.append(ll)

        content.append('TER')
        fs.safe_rm(temp_fname)

    content.pop()
    content.append('END')

    outfile = Path(conformers).with_suffix('.pdb')
    fs.write_lines(outfile, content)
    return str(outfile)


def protonate_ligand(molfile: str) -> str:
    """ """
    local = eh.interface.pymol.convert(molfile, new_ext='.mol2')
    local = eh.interface.pymol.de_protonate(local)
    protonated = eh.interface.moe.protonate(local)
    return eh.interface.pymol.convert(protonated, new_ext='.sdf')


def log_elapsed_time(elapsed: int) -> None:
    """ """
    days, hours, minutes, seconds = 0, 0, 0, 0

    minutes_denom = 60
    hours_denom = minutes_denom * 60
    days_denom = hours_denom * 24

    if elapsed >= days_denom:
        days = int(elapsed / days_denom)
        elapsed //= days_denom

    if elapsed >= hours_denom:
        hours = int(elapsed / hours_denom)
        elapsed //= hours_denom

    if elapsed >= minutes_denom:
        minutes = int(elapsed / minutes_denom)
        elapsed //= minutes_denom

    seconds = int(elapsed)

    eh.core._LOGGER.info(
        f"Elapsed time: {days} days {hours} hours {minutes} minutes {seconds} seconds"
    )


def log_results(score_file: str, top_n: int) -> str:
    """ """
    df: pd.DataFrame = eh.interface.rosetta.parse_score_file(score_file)
    #show top 5
    df.sort_values(by='total_score', inplace=True)
    df.reset_index(drop=True, inplace=True)
    idx = min(top_n, len(df))
    eh.core._LOGGER.info(f"EnzyRCD run complete. Top {idx} structures are:")
    eh.core._LOGGER.info(f"No. \t    REU\t Structure")

    for i, row in df.iterrows():
        if i == idx:
            break
        eh.core._LOGGER.info(
            f"{i+1: 3}\t{row.total_score:6.2f}\t{row.description}")

    outfile: str = Path(score_file).with_suffix('.csv')
    df.to_csv(outfile, index=False)
    return outfile


def parse_mol2(fname: str):

    fh = open(fname, 'r')
    lines = fh.read().splitlines()
    fh.close()

    lines.reverse()

    temp = None

    atom_mapper = dict()
    connection_mapper = defaultdict(list)

    while lines:

        temp = lines.pop()

        if not temp or temp.startswith('#'):
            temp = lines.pop()
            continue

        if temp.find('@<TRIPOS>ATOM') != -1:
            temp = lines.pop()
            while temp.find('@') == -1:
                (num, name, _) = temp.split(maxsplit=2)
                atom_mapper[int(num)] = name
                temp = lines.pop()

        if temp.find('@<TRIPOS>BOND') != -1:
            temp = lines.pop()
            while temp.find('@') == -1:
                (_, n1, n2, btype) = temp.split()
                n1, n2 = int(n1), int(n2)
                connection_mapper[n1].append((n2, btype))
                connection_mapper[n2].append((n1, btype))
                temp = lines.pop()

    return (atom_mapper, connection_mapper)


def no_aromatics(bonds):
    for (prtner, btype) in bonds:
        if btype == 'ar':
            return False
    return True


def is_dead_end(anum, cmapper):
    return len(cmapper[anum]) == 1


def dead_end_aromatics_only(anum, cmapper):
    for (nn, btype) in cmapper[anum]:
        if btype != 'ar':
            continue
        if not is_dead_end(nn, cmapper):
            return False

    return True


def kekulize(in_file: str, out_format: str = '.sdf') -> str:
    """ """

    mol = Chem.MolFromMol2File(str(in_file),
                               removeHs=False,
                               cleanupSubstructures=False,
                               sanitize=False)

    holder = defaultdict(list)
    for bb in mol.GetBonds():
        if bb.IsInRing() or not bb.GetIsAromatic():
            continue
        holder[bb.GetBeginAtomIdx()].append(bb.GetEndAtomIdx())

    doubles = list()

    for kk, vv in holder.items():
        doubles.append((kk, np.random.choice(vv)))

    for bidx in range(mol.GetNumBonds()):
        bb = mol.GetBondWithIdx(bidx)

        if bb.IsInRing() or not bb.GetIsAromatic():
            continue
        key = (bb.GetBeginAtomIdx(), bb.GetEndAtomIdx())

        mol.GetAtomWithIdx(key[0]).SetIsAromatic(False)
        mol.GetAtomWithIdx(key[1]).SetIsAromatic(False)

        if key in doubles:
            bb.SetBondType(Chem.BondType.DOUBLE)
        else:
            bb.SetBondType(Chem.BondType.SINGLE)

    outfile = Path(in_file).with_suffix(out_format)

    if out_format == '.sdf':
        w = Chem.SDWriter(str(outfile))
        w.SetKekulize(True)
        w.write(mol)
        w.close()
    elif out_format == '.mol2':
        temp_file = Path(outfile).with_suffix('.mol')
        Chem.MolToMolFile(mol, str(temp_file))
        eh.interface.pymol.convert(temp_file, new_ext='.mol2')
        fs.safe_rm(temp_file)

    return str(outfile)


def prepare_ligand(molfile: str, res_code: str,
                   params: ValidatedArgs) -> Dict[str, str]:
    """Convenience method that fully prepares a supplied ligand for the upcoming steps/aspects of 
    the EnzyRCD pipeline. A number of temporary files are created, so the result is a dictionary
    which maps diffrent versions of the ligand to their respective local paths. 

    Arguments:
        molfile: Path to the input ligand file.
        res_code: The three letter PDB code for the ligand. MUST BE L01 or L02.
        params: The ValidatedArgs namedtuple() that comes from the parse_args() function.

    Returns:
        A Dict[str,str] mapping different versions of the ligand to their respective local paths.

    """
    #TODO(CJ): need to check that res_code is either L01 or L02
    #TODO(CJ): should probably check that the ligand is in the correct format -> maybe this isn't
    # necessary since it's checked elsewhere
    file_mapper: Dict[str, str] = {'input': str(molfile)}
    file_mapper['deprotonated'] = eh.interface.pymol.de_protonate(
        file_mapper['input'])
    file_mapper['deprotonated'] = kekulize(file_mapper['deprotonated'],
                                           '.mol2')
    file_mapper['protonated'] = eh.interface.moe.protonate(
        file_mapper['deprotonated'])
    (params_file, pdb_file) = eh.interface.rosetta.parameterize_ligand(
        file_mapper['protonated'], res_code)
    file_mapper['params'] = params_file
    file_mapper['pdb'] = pdb_file
    file_mapper['kekulized'] = kekulize(file_mapper['protonated'])
    file_mapper['conformers'] = eh.interface.bcl.generate_conformers(
        file_mapper['kekulized'])
    file_mapper['conformer_library'] = fix_conformers(
        file_mapper['pdb'], file_mapper['conformers'], res_code)
    file_mapper['conformer_library'] = shutil.move(
        file_mapper['conformer_library'],
        Path(params.work_dir) / Path(file_mapper['conformer_library']).name)
    eh.interface.rosetta.add_conformers(file_mapper['params'],
                                        file_mapper['conformer_library'])

    file_mapper['params'] = shutil.move(
        file_mapper['params'],
        Path(params.work_dir) / Path(file_mapper['params']).name)
    #TODO(CJ): need to move the conformers here and set them up correctly
    return file_mapper


def place_ligands(
        stru_file:str,
        params: ValidatedArgs
        ) -> str:
    """Method that places the respective ligands in the structure

    Arguments:

    Returns:

    """
    #TODO(CJ): need to adjust grid search size based on how confidently 
    # we can place the ligands.
    eh.core._LOGGER.info("Beginning ligand placement protocol...")
    #TODO(CJ): figure out the "EnzyHTP" way of loading the residue names
    cmd.delete('all')
    cmd.load(stru_file)
    stored.holder = []
    cmd.iterate('all', 'stored.holder.append((chain, resi, resn))')
    stored.holder = sorted(list(set(stored.holder)))

    ct = sum([pr[-1] in "L01 L02".split() for pr in stored.holder])

    if ct == 2:
        #TODO(CJ): implement errors for this stuff
        # potential issues we can have:
        # 1. placed, but atom names are NOT unique
        # 2. multiple instances of the ligands
        eh.core._LOGGER.info(
            "L01 and L02 are already found in structure. No ligand placement necessary!"
        )
        return stru_file 
    else:
        #TODO(CJ): This is where more stuff has to happen... alphafill etc
        eh.core._LOGGER.info("Finished ligand placement protocol!")
        return None


def add_constraints(current_structure: str,
                    params: ValidatedArgs) -> Tuple[str, str]:
    """ """
    current_structure = Path(current_structure)
    cst_file, pdb_with_csts = str(
        current_structure.parent / "RDock.cst"
    ), f"{current_structure.parent}/{current_structure.stem}_csts.pdb"

    cst_content: List[str] = list()
    #TODO(CJ): put in some kind of header here

    res_mappings = list()

    for cidx, cst in enumerate(params.constraints):
        #TODO(CJ): need to check that the residues are legit -> Either a three residue code
        # or L01/L02
        if cst_content:
            cst_content.append("")

        res_mappings.append(
            f"REMARK 666 MATCH TEMPLATE {cst.rchain_1} {cst.rname_1}  {cst.rnum_1} MATCH MOTIF {cst.rchain_2} {cst.rname_2}  {cst.rnum_2}  {cidx+1}  1"
        )

        cst_content.append("CST::BEGIN")
        cst_content.append(
            f"   TEMPLATE::  ATOM_MAP: 1 atom_name: {' '.join(cst.ratoms_1)}")
        cst_content.append(
            f"   TEMPLATE::  ATOM_MAP: 1 residue3: {cst.rname_1}")
        cst_content.append("")
        cst_content.append(
            f"   TEMPLATE::  ATOM_MAP: 2 atom_name: {' '.join(cst.ratoms_2)}")
        cst_content.append(
            f"   TEMPLATE::  ATOM_MAP: 2 residue3: {cst.rname_2}")
        cst_content.append("")

        for ridx, rule in enumerate(cst.constraints):
            cst_content.append(
                f"   CONSTRAINT::  {rule[0]}: {rule[1]} {rule[2]} {rule[3]} {ridx}"
            )

        cst_content.append("CST::END")

    fs.write_lines(cst_file, cst_content)

    content: List[str] = [
        "HEADER                                            xx-MMM-xx",
    ] + res_mappings
    content.extend(fs.lines_from_file(current_structure))
    fs.write_lines(pdb_with_csts, content)

    return (pdb_with_csts, cst_file)



def handle_temp_files( params :ValidatedArgs, mapper1:Dict[str,str], mapper2:Dict[str,str] ) -> None:
    """ """
    for mapper in [mapper1, mapper2]:
        for ftype, fname in mapper.items():
            if ftype == 'input':
                continue
            
            fpath = Path( fname )
            if params.temp_handling == 'work_dir':
                #TODO(CJ): need to turn ths into a function 
                shutil.move( fname, params.work_dir + "/"  + str( fpath.name) )
            else:
                fs.safe_rm( fname )
    
    fs.safe_rm( Path(params.work_dir) / "score.sc" )
    fs.safe_rm( Path(params.work_dir) / "RDock.cst" )
    fs.safe_rm( Path(params.work_dir) / "ROSETTA_CRASH.log" ) #TODO(CJ): probably should be a rosetta thing


def main(params: ValidatedArgs) -> None:
    """ Main routine """
    #TODO(CJ): actually use the pH that is supplied
    #TODO(CJ): need to change all occupancies to 1.00 if needed
    
    #TODO(CJ): canonicalize the system -> Update the chains, mutations and constraints 

    start = time.time()
    fs.safe_mkdir(params.work_dir)
    #TODO(CJ): give option to give the conformer files ahead of time
    #1. Mutate if necessary
    if params.mutations:
        eh.mutate_pdb(params.structure,
                      mutations=params.mutation,
                      engine='rosetta')
        #TODO(CJ): relax here                      

    #TODO(CJ): make the work_dir if it doesnt exist

    current_structure = params.structure

    if params.protonate_structure:
        parser = eh.structure.PDBParser()
        structure = parser.get_structure(params.structure)
        eh.preparation.protonate_stru(structure, ph=params.pH)
        content:str = parser.get_file_str(structure)
        content=re.sub('HID|HIE','HIS',content)
        prot = Path( params.structure )
        new_name = f"{prot.parent}/{prot.stem}_prot.pdb"
        fs.write_lines(new_name, content.splitlines())
        current_structure = new_name

    #TODO(CJ): need to do relaxation here and also write out the structure

    l1_fm: Dict[str, str] = prepare_ligand(params.ligand_1, 'L01', params)

    if params.ligand_2:
        l2_fm: Dict[str, str] = prepare_ligand(params.ligand_2, 'L02', params)

    current_structure = place_ligands(current_structure, params)
    (current_structure, cst_file) = add_constraints(current_structure, params)

    (options_file, score_file) = make_options_file(
        current_structure,
        params,
        lig_params_1=l1_fm['params'],
        lig_params_2=l2_fm['params'] if params.ligand_2 else None,
        work_dir=Path(params.structure).parent,
        cst_file=cst_file)

    fs.safe_rm(score_file)
    #fs.safe_rm( l1_fm[1] )
    #fs.safe_rm( ligand_2_parameters[1] )
    start_dir: str = os.getcwd()

    eflags: List[str] = ['-in:file:extra_res_fa', str(l1_fm['params'])]

    if params.ligand_2:
        eflags.extend(['-in:file:extra_res_fa', str(l2_fm['params'])])

    start_score: float = eh.interface.rosetta.score(current_structure,
                                                    extra_flags=eflags)

    if start_score >= 0.0:
        eh.core._LOGGER.error(
            f"The starting structure has a REU >= 0 ({start_score:.3f}). Relax/minmize the starting structure and re-run EnzyRCD on it. Exiting..."
        )
        exit(1)

    os.chdir(params.work_dir)
    eh.interface.rosetta.run_rosetta_scripts([f"@options.txt"])
    os.chdir(start_dir)

    score_csv: str = log_results(score_file, params.top_n)

    handle_temp_files( params, l1_fm, l2_fm  ) 

    elapsed = time.time() - start
    log_elapsed_time(elapsed)


if __name__ == '__main__':
    main(parse_args())
